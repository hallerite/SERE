# Symbolic Embodied Reasoning Environments (SERE)

**SERE** is a lightweight framework for building **symbolic, embodied reasoning environments** â€” where agents must manipulate objects, respect spatial and causal constraints, and satisfy task goals expressed in PDDL-style logic.

Itâ€™s designed for **RL + LLM training**, giving you a **Gym-style API** but with symbolic state, grounded actions, stochasticity, and reward shaping built in.

---

## âœ¨ Features

- **YAML-defined domains** â€“ types, predicates, fluents, actions (with preconditions, add/del, conditional and numeric effects).  
- **PDDL-style grounding** â€“ parses `(pick-up r1 mug1)` into concrete state updates.  
- **World state engine** â€“ maintains objects, facts, numeric fluents, and enforces invariants.  
- **Numeric fluents, durations, energy** â€“ model time, resources, and stochastic outcomes.  
- **Reward shaping & termination rules** â€“ instant milestones, potential-based shaping, and flexible episode outcomes.  
- **Invariant plugins** â€“ register domain-specific constraints (e.g. â€œobject canâ€™t be in two placesâ€).  
- **Human-readable rendering** â€“ natural language + PDDL observations for LLM prompting, with affordance lists.  
- **Reference plans & regression tests** â€“ validate domains and ensure backward compatibility.  

---

## ğŸ— Architecture

```
src/sere/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ world_state.py       # Facts, objects, fluents, invariants
â”‚   â”œâ”€â”€ semantics.py         # Clause + numeric evaluation, traces
â”‚   â”œâ”€â”€ invariants.py        # Generic + domain-specific plugins
â”‚   â””â”€â”€ pddl_env/            # RL-style environment + prompting
â”‚       â”œâ”€â”€ env.py           # Env: reset/step/reward/done
â”‚       â”œâ”€â”€ engine.py        # Action application, stochastic outcomes
â”‚       â”œâ”€â”€ planning.py      # Parse/execute action blocks
â”‚       â”œâ”€â”€ rendering.py     # Messages + obs stitching
â”‚       â”œâ”€â”€ prompt_formatter.py # System prompt + observations + affordances
â”‚       â””â”€â”€ run_mode.py      # interactive / batch / open_loop
â”‚
â”œâ”€â”€ pddl/                    # Domain parsing, grounding, NL mapping
â”œâ”€â”€ io/                      # Task loader utilities
â”œâ”€â”€ cli/                     # Command-line runner
â”‚   â””â”€â”€ run_task.py
â””â”€â”€ assets/
    â”œâ”€â”€ domain/              # Domain YAMLs (kitchen, assembly, â€¦)
    â””â”€â”€ tasks/               # Task YAMLs (per domain)
```

---

## ğŸ”§ Installation

```bash
git clone https://github.com/yourname/SERE.git
cd SERE
uv venv .venv
source .venv/bin/activate
uv sync
```

Requires **Python 3.11+**.

---

## â–¶ï¸ Running a Task

From the repo root:

```bash
python -m sere.cli.run_task kitchen/t01_one_step_steep.yaml
```

Note: `cli.run_task` looks at `src/sere/assets/tasks/` for the `yaml` file.

Youâ€™ll see output like:

```
...
State:
  (at r1 hallway)
  (obj-at kettle1 kitchen)
  (clear-hand r1)
Goal:
  (tea-ready mug1)

Reply with (action args).
```

Example step:

```
(move r1 hallway kitchen)
```

The environment will parse and apply the action, update time/energy, and return the next observation plus reward.

---

## ğŸ›  Authoring Domains & Tasks

- **Domains** (`assets/domain/*.yaml`) define:
  - **Types** (`robot`, `location`, `object`, â€¦)  
  - **Predicates** (`at`, `holding`, `in`, â€¦)  
  - **Fluents** (`energy`, `time`, â€¦)  
  - **Actions** (with preconditions, add/del, conditional effects, stochastic outcomes, numeric updates, durations)

- **Tasks** (`assets/tasks/**/*.yaml`) define:
  - **Objects** with types  
  - **Initial state** (facts + fluent values)  
  - **Statics** (e.g. adjacency graph)  
  - **Goals** (logical literals or conditions)  
  - **Optional shaping rules** and **reference plans**  

This separation makes it easy to randomize tasks or auto-generate curricula.

## To Do
- improve docs
- add domain randomization for tasks
    - multiple different distinct outcomes for some actions